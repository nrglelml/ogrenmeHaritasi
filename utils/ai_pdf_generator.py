import os
import re
import json
import wikipedia
import requests
import matplotlib


matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import numpy as np
import pandas as pd
from openai import OpenAI
from weasyprint import HTML
from weasyprint.text.fonts import FontConfiguration
from jinja2 import Template
from datetime import datetime
from .sanitize import sanitize_filename
from dotenv import load_dotenv
import textwrap
from youtubesearchpython import VideosSearch
from duckduckgo_search import DDGS
import urllib.parse


load_dotenv()


client = OpenAI(
    base_url="https://api.groq.com/openai/v1",
    api_key=os.getenv("GROQ_API_KEY")
)

AI_MODEL = "llama-3.3-70b-versatile"


def get_ai_learning_plan_and_steps(topic, problems=None, guidance=None, duration=None):
    # KÄ°ÅÄ°SELLEÅTÄ°RME MESAJI OLUÅTURMA
    # EÄŸer veri setinden (routes.py'den) veri geldiyse burasÄ± dolar
    personalization_note = ""
    if problems and len(problems) > 0:
        personalization_note = (
            f"DÄ°KKAT - Ã–ÄRENCÄ° VERÄ°SÄ° MEVCUT: Bu Ã¶ÄŸrenci analizlerimize gÃ¶re ÅŸu problem tiplerinde zorlanÄ±yor: {', '.join(map(str, problems[:5]))}. "
            "LÃ¼tfen hazÄ±rlayacaÄŸÄ±n planda bu zayÄ±f noktalarÄ± gÃ¼Ã§lendirecek pratiklere EKSTRA aÄŸÄ±rlÄ±k ver. "
            "Ã–ÄŸrencinin baÅŸarÄ± ortalamasÄ± analiz edildi ve seviyesi buna gÃ¶re belirlendi."
        )
    else:
        personalization_note = "Ã–ÄŸrenci hakkÄ±nda geÃ§miÅŸ veri yok. Bu yÃ¼zden konuyu sÄ±fÄ±rdan alan, herkes iÃ§in uygun en kapsamlÄ± rehberi hazÄ±rla."

    # PROMPT AYARLARI (DetaylÄ± PDF Ä°Ã§in)
    style_guide = """
    Ã‡IKTI FORMATI: Sadece HTML kodu.
    Ä°Ã‡ERÄ°K ZORUNLULUKLARI:
    1. 'Kaynak Ã–nerileri' bÃ¶lÃ¼mÃ¼ MUTLAKA olacak (<a> etiketli linkler).
    2. 'GÃ¼nlÃ¼k Rutin' bÃ¶lÃ¼mÃ¼ MUTLAKA olacak.
    3. Tablolar CSS ile stillendirilmiÅŸ olacak.
    """

    if duration:
        scenario = f"KullanÄ±cÄ± '{topic}' konusunu '{duration}' sÃ¼rede bitirmek istiyor. {duration} sÃ¼resine uygun haftalÄ±k/aylÄ±k detaylÄ± tablo oluÅŸtur."
    else:
        scenario = f"KullanÄ±cÄ± '{topic}' konusunu A'dan Z'ye Ã¶ÄŸrenmek istiyor. Seviye bazlÄ± (BaÅŸlangÄ±Ã§-Orta-Ä°leri) detaylÄ± tablo oluÅŸtur."

    full_prompt = f"""
    Sen uzman bir eÄŸitim koÃ§usun. Konu: {topic}.

    {personalization_note}

    {scenario}

    {style_guide}

    CevabÄ±n en altÄ±na ===STEPS=== ekleyip yol haritasÄ± adÄ±mlarÄ±nÄ± listele.
    """

    # ... (AI Ã§aÄŸÄ±rma ve PDF oluÅŸturma kÄ±sÄ±mlarÄ± aynÄ±, Ã¶nceki cevaptaki zengin prompt yapÄ±sÄ±nÄ± kullanÄ±yor) ...
    # Buradaki kodun kalanÄ± Ã¶nceki cevaptaki "generate_two_pdfs_hybrid" ile aynÄ±dÄ±r.
    # Ã–NEMLÄ° OLAN: personalization_note kÄ±smÄ±nÄ± eklememizdi.

    # Kodu kÄ±saltmak iÃ§in tekrar yazmÄ±yorum, Ã¶nceki cevaptaki logic aynen geÃ§erli.
    # Sadece full_prompt iÃ§ine personalization_note eklediÄŸinden emin ol.

    try:
        response = client.chat.completions.create(
            model=AI_MODEL,
            messages=[{"role": "user", "content": full_prompt}],
            temperature=0.5
        )
        content = response.choices[0].message.content
        # ... Regex iÅŸlemleri aynÄ± ...
        plan_match = re.search(r"(.*?)===STEPS===", content, re.S)
        steps_match = re.search(r"===STEPS===\s*(.*)", content, re.S)

        plan_html = plan_match.group(1).strip() if plan_match else content.replace("===STEPS===", "")
        steps = steps_match.group(1).strip().split("\n") if steps_match else []

        return plan_html, steps
    except Exception as e:
        return f"<p>Hata: {e}</p>", []



def export_resources_pdf(topic, ai_plan_html, filename, duration=None):
    subtitle = f"Hedef SÃ¼re: {duration}" if duration else "KapsamlÄ± Ã–ÄŸrenme Rehberi"

    html_template = """
    <html>
    <head>
        <style>
            @page { margin: 2cm; }
            body { font-family: 'Helvetica', sans-serif; line-height: 1.6; color: #333; }
            h1 { color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; }
            h3 { color: #e67e22; margin-top: 25px; border-left: 5px solid #e67e22; padding-left: 10px; }
            table { width: 100%; border-collapse: collapse; margin-top: 15px; font-size: 0.9em; }
            th, td { border: 1px solid #ddd; padding: 12px; text-align: left; }
            th { background-color: #f2f2f2; color: #2c3e50; }
            tr:nth-child(even) { background-color: #f9f9f9; }
            a { color: #2980b9; text-decoration: none; font-weight: bold; }
            ul { margin-top: 0; }
            .meta { font-size: 0.8em; color: #777; margin-bottom: 30px; }
        </style>
    </head>
    <body>
        <h1>Ã–ÄŸrenme PlanÄ±: {{ topic }}</h1>
        <div class="meta">
            <strong>Tarih:</strong> {{ date }} <br>
            <strong>Program TÃ¼rÃ¼:</strong> {{ subtitle }}
        </div>

        {{ ai_plan | safe }}

    </body>
    </html>
    """

    template = Template(html_template)
    rendered_html = template.render(
        topic=topic,
        subtitle=subtitle,
        date=datetime.today().strftime("%d.%m.%Y"),
        ai_plan=ai_plan_html
    )

    try:
        font_config = FontConfiguration()
        HTML(string=rendered_html).write_pdf(filename, font_config=font_config)
    except Exception as e:
        print(f"PDF oluÅŸturma hatasÄ±: {e}")


def generate_two_pdfs_hybrid(user_input, df_with_skills, output_dir="outputs", duration=None):
    safe_topic = sanitize_filename(user_input)
    if not os.path.exists(output_dir): os.makedirs(output_dir)

    problems = []
    # VERÄ° ANALÄ°ZÄ° (Hibrit KÄ±sÄ±m)
    if not df_with_skills.empty:
        try:
            # Correct sÃ¼tununu sayÄ±ya Ã§evir
            df_with_skills["correct"] = pd.to_numeric(df_with_skills["correct"], errors='coerce')
            # En Ã§ok yanlÄ±ÅŸ yapÄ±lan problem ID'lerini bul
            difficulty = df_with_skills.groupby("problem_id")["correct"].mean()
            problems = difficulty.sort_values().head(5).index.tolist()
            print(f" Veri Analizi Sonucu: Ã–ÄŸrenci {problems} konularÄ±nda zayÄ±f.")
        except:
            pass

    # Analiz sonuÃ§larÄ±nÄ± (problems) AI'ya gÃ¶nder
    ai_plan_html, steps = get_ai_learning_plan_and_steps(user_input, problems, None, duration)

    export_resources_pdf(user_input, ai_plan_html, os.path.join(output_dir, f"{safe_topic}_resources.pdf"), duration)
    if steps:
        create_timeline_pdf(steps, os.path.join(output_dir, f"{safe_topic}_roadmap.pdf"))

    return safe_topic



# --- Timeline PDF ---
def create_timeline_pdf(steps, filename):
    try:
        num_steps = len(steps)


        fig_height = max(8, num_steps * 1.2)
        fig, ax = plt.subplots(figsize=(8, fig_height))
        ax.axis('off')

        y_positions = np.linspace(num_steps, 0, num_steps)

        x_positions = np.sin(np.linspace(0, num_steps, num_steps) * 1.5) * 2

        ax.plot(x_positions, y_positions, color='#bdc3c7', linewidth=4, linestyle='--', zorder=1, alpha=0.5)

        colors = ['#e74c3c', '#3498db', '#9b59b6', '#2ecc71', '#f1c40f', '#34495e']

        for i, (x, y, text) in enumerate(zip(x_positions, y_positions, steps)):

            color = colors[i % len(colors)]


            circle = mpatches.Circle((x, y), 0.3, color=color, zorder=3)
            ax.add_patch(circle)


            ax.text(x, y, str(i + 1), color='white', ha='center', va='center',
                    fontsize=10, fontweight='bold', zorder=4)


            text_offset_x = 0.6 if x >= 0 else -0.6
            ha_align = 'left' if x >= 0 else 'right'


            wrapped_text = "\n".join(textwrap.wrap(text, width=25))


            ax.text(x + text_offset_x, y, wrapped_text,
                    ha=ha_align, va='center', fontsize=11, color='#2c3e50', weight='bold',
                    bbox=dict(boxstyle="round,pad=0.4", fc="white", ec=color, lw=1.5, alpha=0.9),
                    zorder=5)


        ax.set_xlim(-5, 5)
        ax.set_ylim(-1, num_steps + 1)


        os.makedirs(os.path.dirname(filename), exist_ok=True)


        plt.savefig(filename, bbox_inches='tight', dpi=150)
        plt.close()

    except Exception as e:
        print(f"Timeline PDF hatasÄ±: {e}")





try:
    wikipedia.set_lang("tr")
except:
    pass


def get_wikipedia_summary(topic):
    try:
        summary = wikipedia.summary(topic, sentences=2)
        page = wikipedia.page(topic)
        return {"title": page.title, "summary": summary, "url": page.url}
    except:
        return None


def is_safe_language(text):
    """
    Ä°Ã§eriÄŸin TÃ¼rkÃ§e veya Ä°ngilizce olup olmadÄ±ÄŸÄ±nÄ± kontrol eder.
    Ã‡ince, Japonca, Korece, Kiril vb. karakterler varsa False dÃ¶ner.
    """
    if not text: return False

    # Ã‡ince, Japonca, Korece karakter aralÄ±ÄŸÄ± (CJK Unified Ideographs)
    if re.search(r'[\u4e00-\u9fff]', text):
        return False
    # RusÃ§a (Kiril) karakter aralÄ±ÄŸÄ± (Ä°steÄŸe baÄŸlÄ±, O-RAN RusÃ§a da Ã§Ä±kabilir)
    if re.search(r'[\u0400-\u04FF]', text):
        return False

    return True


def get_real_resources(topic):
    results = {
        "Wikipedia": [],
        "Videos": [],
        "Articles": [],
        "Courses": []
    }

    safe_topic = urllib.parse.quote_plus(topic)
    topic_lower = topic.lower()

    # ---------------------------------------------------------
    # 1. GARANTÄ°LÄ° KAYNAKLAR (Hardcoded)
    # ---------------------------------------------------------

    # Sadece YAZILIM konularÄ±nda W3Schools gÃ¶ster (Matematikte gÃ¶sterme)
    coding_keywords = ['python', 'java', 'html', 'css', 'javascript', 'sql', 'c#', 'c++', 'react', 'php', 'yazÄ±lÄ±m',
                       'kodlama']
    if any(k in topic_lower for k in coding_keywords):
        results["Articles"].append({
            "title": f"{topic} - W3Schools Rehberi",
            "url": f"https://www.w3schools.com/{topic.split()[0].lower()}/",
            "desc": "YazÄ±lÄ±m Ã¶ÄŸrenmek iÃ§in en popÃ¼ler kaynak."
        })

        # Medium (YazÄ±lÄ±m iÃ§in iyidir)
        results["Articles"].append({
            "title": f"Medium: {topic} Makaleleri",
            "url": f"https://medium.com/search?q={safe_topic}",
            "desc": "Uzman yazÄ±lÄ±mcÄ±larÄ±n makaleleri."
        })
    else:
        # MATEMATÄ°K veya DÄ°ÄER konular iÃ§in garanti kaynaklar (Khan Academy vb.)
        results["Articles"].append({
            "title": f"Khan Academy: {topic}",
            "url": f"https://tr.khanacademy.org/search?page_search_query={safe_topic}",
            "desc": "Ãœcretsiz, dÃ¼nya standartlarÄ±nda eÄŸitim."
        })

    # Udemy & Coursera (Her konu iÃ§in geÃ§erli)
    results["Courses"].append({
        "title": f"Udemy: {topic} KurslarÄ±",
        "url": f"https://www.udemy.com/courses/search/?q={safe_topic}",
        "desc": "Udemy Ã¼zerindeki en yÃ¼ksek puanlÄ± kurslar."
    })

    results["Courses"].append({
        "title": f"Youtube: {topic} Oynatma Listeleri",
        "url": f"https://www.youtube.com/results?search_query={safe_topic}+dersleri&sp=EgIQAw%253D%253D",
        # Playlist filtresi
        "desc": "Konuyla ilgili Ã¼cretsiz video serileri."
    })

    # ---------------------------------------------------------
    # 2. DÄ°NAMÄ°K ARAMA (Filtreli)
    # ---------------------------------------------------------

    # WIKIPEDIA
    wiki_data = get_wikipedia_summary(topic)
    if wiki_data: results["Wikipedia"].append(wiki_data)

    # YOUTUBE (Video Arama)
    try:
        # AramayÄ± Ã¶zelleÅŸtir: "Konu + ders anlatÄ±mÄ± tÃ¼rkÃ§e"
        search_query = f"{topic} ders anlatÄ±mÄ± tÃ¼rkÃ§e"
        print(f"ğŸ¥ Youtube aranÄ±yor: {search_query}")

        videos_search = VideosSearch(search_query, limit=3)
        videos_result = videos_search.result()

        for video in videos_result['result']:
            # BaÅŸlÄ±kta Ã‡ince var mÄ± kontrol et
            if is_safe_language(video['title']):
                results["Videos"].append({
                    "title": video['title'],
                    "url": video['link'],
                    "desc": f"Kanal: {video['channel']['name']} | {video.get('duration', '')}",
                    "thumbnail": video['thumbnails'][0]['url']
                })
    except Exception as e:
        print(f"Youtube HatasÄ±: {e}")

    # WEB MAKALELERÄ° (DuckDuckGo - SÄ±kÄ± Filtreli)
    try:
        # AramayÄ± eÄŸitim odaklÄ± yapÄ±yoruz: "Konu + nedir + konu anlatÄ±mÄ±"
        web_query = f"{topic} konu anlatÄ±mÄ± ders notlarÄ± nedir"
        print(f"ğŸŒ Web aranÄ±yor: {web_query}")

        with DDGS() as ddgs:
            # TÃ¼rkiye bÃ¶lgesi, GÃ¼venli Arama AÃ§Ä±k
            ddg_results = list(ddgs.text(web_query, region='tr-tr', safesearch='on', max_results=4))

            for res in ddg_results:
                title = res['title']
                body = res['body']

                # --- FÄ°LTRELEME MOTORU ---
                # 1. W3Schools zaten eklediysek atla
                if "w3schools" in res['href']: continue

                # 2. Ã‡ince/YabancÄ± karakter kontrolÃ¼ (O-RAN sorunu iÃ§in)
                if not is_safe_language(title) or not is_safe_language(body):
                    print(f"ğŸš« YabancÄ± kaynak engellendi: {title}")
                    continue

                results["Articles"].append({
                    "title": title,
                    "url": res['href'],
                    "desc": body[:100] + "..."
                })

    except Exception as e:
        print(f"Web Arama HatasÄ±: {e}")

    return results


# Wrapper
def get_ai_resources(topic):
    return get_real_resources(topic)

